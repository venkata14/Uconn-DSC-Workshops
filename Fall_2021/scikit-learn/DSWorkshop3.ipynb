{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSWorkshop3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNIkqahBTWuU"
      },
      "source": [
        "Notebook created by Alex H. Chen and Venkata Patchigolla"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wKjz0wQZTB6"
      },
      "source": [
        "# What is Linear Regression?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Efr60GVe1CV8"
      },
      "source": [
        "Linear regression is used for applications in which one is trying to predict a scalar value. \n",
        "\n",
        "**Simple Linear Regression**\n",
        "\n",
        "y=mx+b\n",
        "\n",
        "**Multiple Linear Regression**\n",
        "\n",
        "y=a<sub>1</sub>x<sub>1</sub>+a<sub>2</sub>x<sub>2</sub>+a<sub>3</sub>x<sub>3</sub>+a<sub>4</sub>x<sub>4</sub>+...+b\n",
        "\n",
        "**Examples**\n",
        "\n",
        "*   Household income\n",
        "*   Sales\n",
        "*   Height\n",
        "*   Weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWlcuqfa1G_I"
      },
      "source": [
        "# What is Logistic Regression?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQsXL9Pg1Ujy"
      },
      "source": [
        "Recall that linear regression is used for predicting scalar values. For linear regression the output of the model is always a scalar. For logistic regression, on the other hand, the output is a 0 or 1. This makes logistic regression most suitable for classification.\n",
        "\n",
        "**Examples**\n",
        "*   Purchasing a particular product\n",
        "*   Credit card fraud\n",
        "*   Defaulting on a loan\n",
        "*   Spam detection\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ya6ckLW1YM0"
      },
      "source": [
        "# Introduction to Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYogEhxT15XO"
      },
      "source": [
        "Scikit-learn is a Python library that contains the vast majority of popular machine learning algorithms. Scikit-learn is built on NumPy, SciPy, and matplotlib."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vegLVobV8GSd"
      },
      "source": [
        "## Install Scikit-learn\n",
        "\n",
        "*On Windows or Mac*\n",
        "\n",
        "pip install -U scikit-learn\n",
        "\n",
        "*On Linux*\n",
        "\n",
        "pip3 install -U scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT6cWbcc8DJS",
        "outputId": "e362919b-c5a0-4549-a49b-02f8168d4dc9"
      },
      "source": [
        "# Run shell commands in Jupyter Notebooks with the \"!\" symbol\n",
        "!pip install -U scikit-learn\n",
        "!pip install pandas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eim1oy_X-pWw"
      },
      "source": [
        "# Simple Linear Regression Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fcjUMwt_AMI"
      },
      "source": [
        "Recall that a simple linear regression is simply the equation of a straight line with two variables: x and y.\n",
        "\n",
        "y=mx+b\n",
        "\n",
        "Thus, we are essentially trying to find a best fit line with the most accurate intercept and slope to model the data. This could also be done in Excel without any code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im-429Ku8z2i"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvml15GMIGSn"
      },
      "source": [
        "Import the **student_scores** dataset. The dataset has two columns: hours and scores. \n",
        "\n",
        "*   Hours: the number of hours a student spent preparing for the exam\n",
        "*   Score: the score (out of 100) that the student earned on the exam\n",
        "\n",
        "Our goal is to predict any student's exam score given his or her number of hours of preparation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyjFoj0tZR2-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df85d55-0bb7-4bf9-9d83-291301445d6b"
      },
      "source": [
        "# Change the file path to reflect the location of the CSV file.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "df = pd.read_csv('gdrive/My Drive/student_scores.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgyGwowNOWWp"
      },
      "source": [
        "Let's start by exploring the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP13bsl8BQea",
        "outputId": "3b0b3f3c-71ea-4d46-93cc-312094d906bf"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "5hqa7SAnFfd0",
        "outputId": "382e7028-2f37-43fc-a0e6-688e8ca2e6f8"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hours</th>\n",
              "      <th>Scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.5</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.1</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.2</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.5</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.5</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Hours  Scores\n",
              "0    2.5      21\n",
              "1    5.1      47\n",
              "2    3.2      27\n",
              "3    8.5      75\n",
              "4    3.5      30"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "uT18oYH2FeZj",
        "outputId": "73c5afd3-9bb1-45f4-9842-d430d133a859"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hours</th>\n",
              "      <th>Scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>25.000000</td>\n",
              "      <td>25.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.012000</td>\n",
              "      <td>51.480000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.525094</td>\n",
              "      <td>25.286887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.100000</td>\n",
              "      <td>17.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.700000</td>\n",
              "      <td>30.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.800000</td>\n",
              "      <td>47.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.400000</td>\n",
              "      <td>75.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.200000</td>\n",
              "      <td>95.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Hours     Scores\n",
              "count  25.000000  25.000000\n",
              "mean    5.012000  51.480000\n",
              "std     2.525094  25.286887\n",
              "min     1.100000  17.000000\n",
              "25%     2.700000  30.000000\n",
              "50%     4.800000  47.000000\n",
              "75%     7.400000  75.000000\n",
              "max     9.200000  95.000000"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ABtCBUJ6F3vj",
        "outputId": "0a6000ae-ed55-4fa9-cce5-85de662ece91"
      },
      "source": [
        "df.plot(x='Hours', y='Scores', style='o')\n",
        "plt.title('Hours vs Percentage')\n",
        "plt.xlabel('Hours Studied')\n",
        "plt.ylabel('Percentage Score')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuoOF9DnGFbC"
      },
      "source": [
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, 1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnYhWwfQGXZn"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMAEg1hdGaa9",
        "outputId": "2e66cb1c-ff30-4319-e343-8c8321457c1f"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTFWYlEHGhlo",
        "outputId": "e0ccf4d1-baeb-4d2c-837a-eee2ffadcff4"
      },
      "source": [
        "print(reg.intercept_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.018160041434662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iYPQtowGia5",
        "outputId": "928fdc55-2b43-45de-cbc0-ac1196287db7"
      },
      "source": [
        "print(reg.coef_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9.91065648]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgjCxTNHGiXw"
      },
      "source": [
        "y_pred = reg.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "S9yQpWyvK0yC",
        "outputId": "6c6da6cb-7754-40c1-94b4-c643ae619fcf"
      },
      "source": [
        "df.plot(x='Hours', y='Scores', style='o')\n",
        "plt.title('Hours vs Percentage')\n",
        "plt.xlabel('Hours Studied')\n",
        "plt.ylabel('Percentage Score')\n",
        "\n",
        "plt.plot(X_test, y_pred, color='red')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "ijfesT-sGiU0",
        "outputId": "4913e05a-b47c-444f-894e-e6cd5caff730"
      },
      "source": [
        "df2 = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>16.884145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27</td>\n",
              "      <td>33.732261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>69</td>\n",
              "      <td>75.357018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>26.794801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62</td>\n",
              "      <td>60.491033</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Actual  Predicted\n",
              "0      20  16.884145\n",
              "1      27  33.732261\n",
              "2      69  75.357018\n",
              "3      30  26.794801\n",
              "4      62  60.491033"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7msQkmpyGiRz",
        "outputId": "8b9bf24c-05d4-4721-b0bb-dd36375c278a"
      },
      "source": [
        "from sklearn import metrics\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 4.183859899002982\n",
            "Mean Squared Error: 21.598769307217456\n",
            "Root Mean Squared Error: 4.647447612100373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dkExJSgJ4fV"
      },
      "source": [
        "# Multiple Linear Regression Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mVmQTs4M6Qy"
      },
      "source": [
        "Recall that multiple linear regression is simply linear regression with more x variables. It is **NOT** polynomial regression or running simple linear regression multiple times.\n",
        "\n",
        "y=a<sub>1</sub>x<sub>1</sub>+a<sub>2</sub>x<sub>2</sub>+a<sub>3</sub>x<sub>3</sub>+a<sub>4</sub>x<sub>4</sub>+...+b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0p26zBBGiO0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7dh34RgN6Bv"
      },
      "source": [
        "Import the **petrol_consumption** dataset. The dataset has five columns: petrol_tax, average_income, paved_highways, Population_Driver_licence, and petrol_consumption. The dataset measures the consumption of petrol in 48 states for one specific year.\n",
        "\n",
        "*   petrol_tax: the tax on petrol measuring in cents per gallon\n",
        "*   average_income: the average income the state per capita measured in dollars\n",
        "*   paved_highways: the miles of paved highways in the state\n",
        "*   proportional_driver_license: the proportion of individuals in the area with driver's licenses\n",
        "*   petrol_consumption: the consumption of petrol in the state measured in millions of gallons\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daSwtySaGiHo",
        "outputId": "9fd25283-8989-4a1a-f2b9-2e24015cb152"
      },
      "source": [
        "# Change the file path to reflect the location of the CSV file.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "df = pd.read_csv('gdrive/My Drive/petrol_consumption.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKbTXR-4Q6LP"
      },
      "source": [
        "Let's begin by exploring the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RukxkIsE91R",
        "outputId": "dc5c3907-e794-4661-8df6-51e0664341cf"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "PwgcjA1OQ8qR",
        "outputId": "00d3c514-50ac-48fa-e319-bbadfff404bc"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Petrol_tax</th>\n",
              "      <th>Average_income</th>\n",
              "      <th>Paved_Highways</th>\n",
              "      <th>Population_Driver_licence(%)</th>\n",
              "      <th>Petrol_Consumption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.0</td>\n",
              "      <td>3571</td>\n",
              "      <td>1976</td>\n",
              "      <td>0.525</td>\n",
              "      <td>541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.0</td>\n",
              "      <td>4092</td>\n",
              "      <td>1250</td>\n",
              "      <td>0.572</td>\n",
              "      <td>524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.0</td>\n",
              "      <td>3865</td>\n",
              "      <td>1586</td>\n",
              "      <td>0.580</td>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.5</td>\n",
              "      <td>4870</td>\n",
              "      <td>2351</td>\n",
              "      <td>0.529</td>\n",
              "      <td>414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.0</td>\n",
              "      <td>4399</td>\n",
              "      <td>431</td>\n",
              "      <td>0.544</td>\n",
              "      <td>410</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Petrol_tax  Average_income  ...  Population_Driver_licence(%)  Petrol_Consumption\n",
              "0         9.0            3571  ...                         0.525                 541\n",
              "1         9.0            4092  ...                         0.572                 524\n",
              "2         9.0            3865  ...                         0.580                 561\n",
              "3         7.5            4870  ...                         0.529                 414\n",
              "4         8.0            4399  ...                         0.544                 410\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Q9gBYRJhRF7R",
        "outputId": "1dcd988d-5fbc-425d-e9f8-e96ddce2ca9e"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Petrol_tax</th>\n",
              "      <th>Average_income</th>\n",
              "      <th>Paved_Highways</th>\n",
              "      <th>Population_Driver_licence(%)</th>\n",
              "      <th>Petrol_Consumption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.668333</td>\n",
              "      <td>4241.833333</td>\n",
              "      <td>5565.416667</td>\n",
              "      <td>0.570333</td>\n",
              "      <td>576.770833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.950770</td>\n",
              "      <td>573.623768</td>\n",
              "      <td>3491.507166</td>\n",
              "      <td>0.055470</td>\n",
              "      <td>111.885816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>3063.000000</td>\n",
              "      <td>431.000000</td>\n",
              "      <td>0.451000</td>\n",
              "      <td>344.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>3739.000000</td>\n",
              "      <td>3110.250000</td>\n",
              "      <td>0.529750</td>\n",
              "      <td>509.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.500000</td>\n",
              "      <td>4298.000000</td>\n",
              "      <td>4735.500000</td>\n",
              "      <td>0.564500</td>\n",
              "      <td>568.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.125000</td>\n",
              "      <td>4578.750000</td>\n",
              "      <td>7156.000000</td>\n",
              "      <td>0.595250</td>\n",
              "      <td>632.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>5342.000000</td>\n",
              "      <td>17782.000000</td>\n",
              "      <td>0.724000</td>\n",
              "      <td>968.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Petrol_tax  ...  Petrol_Consumption\n",
              "count   48.000000  ...           48.000000\n",
              "mean     7.668333  ...          576.770833\n",
              "std      0.950770  ...          111.885816\n",
              "min      5.000000  ...          344.000000\n",
              "25%      7.000000  ...          509.500000\n",
              "50%      7.500000  ...          568.500000\n",
              "75%      8.125000  ...          632.750000\n",
              "max     10.000000  ...          968.000000\n",
              "\n",
              "[8 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QnGAtFfRSh_"
      },
      "source": [
        "X = df[['Petrol_tax', 'Average_income', 'Paved_Highways', 'Population_Driver_licence(%)']]\n",
        "y = df['Petrol_Consumption']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uop5NWyARXmP"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdWNvTBqRhDe",
        "outputId": "a6a7151a-f658-4f1d-fdb2-94cc98d9bb48"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "8Z-9E-49RmJA",
        "outputId": "28098ad2-ff31-4715-ac8a-4db33d58cc7a"
      },
      "source": [
        "coeff_df = pd.DataFrame(reg.coef_, X.columns, columns=['Coefficient'])\n",
        "coeff_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Petrol_tax</th>\n",
              "      <td>-40.016660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Average_income</th>\n",
              "      <td>-0.065413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Paved_Highways</th>\n",
              "      <td>-0.004741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Population_Driver_licence(%)</th>\n",
              "      <td>1341.862121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              Coefficient\n",
              "Petrol_tax                     -40.016660\n",
              "Average_income                  -0.065413\n",
              "Paved_Highways                  -0.004741\n",
              "Population_Driver_licence(%)  1341.862121"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrkuCH-6Rz7l"
      },
      "source": [
        "y_pred = reg.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "VCYeUm74R391",
        "outputId": "fdd02ddc-064a-495f-bbc9-b5376b94b4e2"
      },
      "source": [
        "df2 = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>534</td>\n",
              "      <td>469.391989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>410</td>\n",
              "      <td>545.645464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>577</td>\n",
              "      <td>589.668394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>571</td>\n",
              "      <td>569.730413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>577</td>\n",
              "      <td>649.774809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>704</td>\n",
              "      <td>646.631164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>487</td>\n",
              "      <td>511.608148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>587</td>\n",
              "      <td>672.475177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>467</td>\n",
              "      <td>502.074782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>580</td>\n",
              "      <td>501.270734</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Actual   Predicted\n",
              "29     534  469.391989\n",
              "4      410  545.645464\n",
              "26     577  589.668394\n",
              "30     571  569.730413\n",
              "32     577  649.774809\n",
              "37     704  646.631164\n",
              "34     487  511.608148\n",
              "40     587  672.475177\n",
              "7      467  502.074782\n",
              "10     580  501.270734"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1x8oiPnSBL6",
        "outputId": "fccec36a-e928-42ba-c755-579d874b775c"
      },
      "source": [
        "from sklearn import metrics\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 56.8222474789647\n",
            "Mean Squared Error: 4666.344787588362\n",
            "Root Mean Squared Error: 68.31064915215168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F4WV6M4WC9R"
      },
      "source": [
        "# Logistic Regression Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXMO-pmmWRo5"
      },
      "source": [
        "Recall that logistic regression is primarily used for classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWS6qqNOWbyu"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdXwHFoPa6HV"
      },
      "source": [
        "Import the digits dataset, which contains 1797 black and white, 8 by 8 images of integers 0-9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt5D2wBNaN5y"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "df=pd.DataFrame(digits.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi01hO04ba3M"
      },
      "source": [
        "Let's begin by exploring the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "RWS-FvHybdLM",
        "outputId": "a64fcdc0-87a3-45fd-e3a6-abcd92f12080"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0    1    2     3     4     5    6   ...   57   58    59    60    61   62   63\n",
              "0  0.0  0.0  5.0  13.0   9.0   1.0  0.0  ...  0.0  6.0  13.0  10.0   0.0  0.0  0.0\n",
              "1  0.0  0.0  0.0  12.0  13.0   5.0  0.0  ...  0.0  0.0  11.0  16.0  10.0  0.0  0.0\n",
              "2  0.0  0.0  0.0   4.0  15.0  12.0  0.0  ...  0.0  0.0   3.0  11.0  16.0  9.0  0.0\n",
              "3  0.0  0.0  7.0  15.0  13.0   1.0  0.0  ...  0.0  7.0  13.0  13.0   9.0  0.0  0.0\n",
              "4  0.0  0.0  0.0   1.0  11.0   0.0  0.0  ...  0.0  0.0   2.0  16.0   4.0  0.0  0.0\n",
              "\n",
              "[5 rows x 64 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "5D0SvgTWX5R7",
        "outputId": "0ca9113a-4199-4707-e831-e4a4ec5fb12d"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1797.0</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.0</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.0</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "      <td>1797.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.303840</td>\n",
              "      <td>5.204786</td>\n",
              "      <td>11.835838</td>\n",
              "      <td>11.848080</td>\n",
              "      <td>5.781859</td>\n",
              "      <td>1.362270</td>\n",
              "      <td>0.129661</td>\n",
              "      <td>0.005565</td>\n",
              "      <td>1.993879</td>\n",
              "      <td>10.382304</td>\n",
              "      <td>11.979410</td>\n",
              "      <td>10.279354</td>\n",
              "      <td>8.175849</td>\n",
              "      <td>1.846411</td>\n",
              "      <td>0.107958</td>\n",
              "      <td>0.002782</td>\n",
              "      <td>2.601558</td>\n",
              "      <td>9.903172</td>\n",
              "      <td>6.992766</td>\n",
              "      <td>7.097941</td>\n",
              "      <td>7.806344</td>\n",
              "      <td>1.788536</td>\n",
              "      <td>0.050083</td>\n",
              "      <td>0.001113</td>\n",
              "      <td>2.469672</td>\n",
              "      <td>9.091263</td>\n",
              "      <td>8.821369</td>\n",
              "      <td>9.927101</td>\n",
              "      <td>7.551475</td>\n",
              "      <td>2.317752</td>\n",
              "      <td>0.002226</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.339455</td>\n",
              "      <td>7.667223</td>\n",
              "      <td>9.071786</td>\n",
              "      <td>10.301614</td>\n",
              "      <td>8.744018</td>\n",
              "      <td>2.909293</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008904</td>\n",
              "      <td>1.583751</td>\n",
              "      <td>6.881469</td>\n",
              "      <td>7.228158</td>\n",
              "      <td>7.672231</td>\n",
              "      <td>8.236505</td>\n",
              "      <td>3.456316</td>\n",
              "      <td>0.027268</td>\n",
              "      <td>0.007234</td>\n",
              "      <td>0.704508</td>\n",
              "      <td>7.506956</td>\n",
              "      <td>9.539232</td>\n",
              "      <td>9.416249</td>\n",
              "      <td>8.758486</td>\n",
              "      <td>3.725097</td>\n",
              "      <td>0.206455</td>\n",
              "      <td>0.000556</td>\n",
              "      <td>0.279354</td>\n",
              "      <td>5.557596</td>\n",
              "      <td>12.089037</td>\n",
              "      <td>11.809126</td>\n",
              "      <td>6.764051</td>\n",
              "      <td>2.067891</td>\n",
              "      <td>0.364496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.907192</td>\n",
              "      <td>4.754826</td>\n",
              "      <td>4.248842</td>\n",
              "      <td>4.287388</td>\n",
              "      <td>5.666418</td>\n",
              "      <td>3.325775</td>\n",
              "      <td>1.037383</td>\n",
              "      <td>0.094222</td>\n",
              "      <td>3.196160</td>\n",
              "      <td>5.421456</td>\n",
              "      <td>3.977543</td>\n",
              "      <td>4.782681</td>\n",
              "      <td>6.052960</td>\n",
              "      <td>3.586321</td>\n",
              "      <td>0.827915</td>\n",
              "      <td>0.062368</td>\n",
              "      <td>3.576301</td>\n",
              "      <td>5.690767</td>\n",
              "      <td>5.802662</td>\n",
              "      <td>6.175729</td>\n",
              "      <td>6.197322</td>\n",
              "      <td>3.259870</td>\n",
              "      <td>0.438597</td>\n",
              "      <td>0.033352</td>\n",
              "      <td>3.146532</td>\n",
              "      <td>6.192038</td>\n",
              "      <td>5.882936</td>\n",
              "      <td>6.152093</td>\n",
              "      <td>5.872556</td>\n",
              "      <td>3.686456</td>\n",
              "      <td>0.047140</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.480372</td>\n",
              "      <td>6.324687</td>\n",
              "      <td>6.268391</td>\n",
              "      <td>5.933490</td>\n",
              "      <td>5.870648</td>\n",
              "      <td>3.537283</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.145185</td>\n",
              "      <td>2.981816</td>\n",
              "      <td>6.537955</td>\n",
              "      <td>6.441378</td>\n",
              "      <td>6.259511</td>\n",
              "      <td>5.695527</td>\n",
              "      <td>4.330951</td>\n",
              "      <td>0.307356</td>\n",
              "      <td>0.204223</td>\n",
              "      <td>1.746153</td>\n",
              "      <td>5.644496</td>\n",
              "      <td>5.226948</td>\n",
              "      <td>5.302048</td>\n",
              "      <td>6.031154</td>\n",
              "      <td>4.919406</td>\n",
              "      <td>0.984401</td>\n",
              "      <td>0.023590</td>\n",
              "      <td>0.934302</td>\n",
              "      <td>5.103019</td>\n",
              "      <td>4.374694</td>\n",
              "      <td>4.933947</td>\n",
              "      <td>5.900623</td>\n",
              "      <td>4.090548</td>\n",
              "      <td>1.860122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0            1            2   ...           61           62           63\n",
              "count  1797.0  1797.000000  1797.000000  ...  1797.000000  1797.000000  1797.000000\n",
              "mean      0.0     0.303840     5.204786  ...     6.764051     2.067891     0.364496\n",
              "std       0.0     0.907192     4.754826  ...     5.900623     4.090548     1.860122\n",
              "min       0.0     0.000000     0.000000  ...     0.000000     0.000000     0.000000\n",
              "25%       0.0     0.000000     1.000000  ...     0.000000     0.000000     0.000000\n",
              "50%       0.0     0.000000     4.000000  ...     6.000000     0.000000     0.000000\n",
              "75%       0.0     0.000000     9.000000  ...    12.000000     2.000000     0.000000\n",
              "max       0.0     8.000000    16.000000  ...    16.000000    16.000000    16.000000\n",
              "\n",
              "[8 rows x 64 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLzxQDTecJ0P"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.20, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "zKfQpKTpb4ci",
        "outputId": "0e89ca61-2cc1-4e08-ca7d-a89d524447a2"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(20,4))\n",
        "for index, (image, label) in enumerate(zip(digits.data[0:10], digits.target[0:10])):\n",
        "  plt.subplot(1, 10, index + 1)\n",
        "  plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray)\n",
        "  plt.title('Training: %i\\n' % label, fontsize = 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZQo4JNMcWhQ"
      },
      "source": [
        "reg=LogisticRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4i66sUKcahw",
        "outputId": "bc540dab-6c9a-41f9-ba53-c2ec69196f90"
      },
      "source": [
        "reg.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTJXEmi2cm-_"
      },
      "source": [
        "pred=reg.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "UqlzEzHHgwK5",
        "outputId": "14dc45e6-e755-4160-92b9-a4eda15a7ce9"
      },
      "source": [
        "df2 = pd.DataFrame({'Actual': y_test, 'Predicted': pred})\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>360 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Actual  Predicted\n",
              "0         2          2\n",
              "1         8          8\n",
              "2         2          2\n",
              "3         6          6\n",
              "4         6          6\n",
              "..      ...        ...\n",
              "355       5          5\n",
              "356       4          4\n",
              "357       3          3\n",
              "358       8          8\n",
              "359       8          8\n",
              "\n",
              "[360 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wdmoUyWc3Lb",
        "outputId": "9c6c7382-5179-4e27-db31-9d29330b9ec3"
      },
      "source": [
        "reg.score(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW1JBQ8n3iLT"
      },
      "source": [
        "## Random Forest Tree Classifier\n",
        "\n",
        "The random forest is a classification algorithm consisting of many decisions trees.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hu79p_r3hKG"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "digits = load_digits()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBem4M5o4f4z",
        "outputId": "b15ac506-65d4-4210-cee8-3b2417d5ab13"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.20, random_state=0)\n",
        "\n",
        "#Classifier\n",
        "clf = RandomForestClassifier(n_estimators=1)\n",
        "clf.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=1,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8admjfr96-XG",
        "outputId": "39410c0c-ba52-4ca0-8734-02607e647234"
      },
      "source": [
        "y_test_predicted = clf.predict(x_test)\n",
        "y_test_predicted"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 8, 2, 6, 6, 7, 1, 9, 8, 5, 2, 1, 6, 6, 6, 6, 9, 0, 5, 8, 8, 7,\n",
              "       2, 4, 7, 5, 4, 9, 2, 9, 4, 7, 6, 1, 9, 4, 3, 1, 0, 1, 8, 6, 7, 7,\n",
              "       1, 0, 7, 6, 2, 1, 9, 6, 7, 8, 4, 0, 5, 1, 6, 3, 0, 3, 3, 4, 2, 2,\n",
              "       2, 4, 8, 1, 8, 3, 5, 1, 2, 8, 2, 3, 9, 7, 2, 3, 6, 0, 9, 5, 7, 8,\n",
              "       1, 2, 3, 9, 3, 1, 1, 7, 4, 8, 5, 1, 5, 5, 3, 5, 9, 0, 7, 1, 4, 1,\n",
              "       3, 8, 8, 9, 7, 9, 4, 0, 6, 5, 2, 5, 8, 4, 1, 7, 0, 6, 1, 5, 5, 9,\n",
              "       9, 5, 9, 9, 8, 7, 5, 6, 2, 2, 6, 9, 6, 1, 5, 1, 4, 9, 9, 9, 9, 3,\n",
              "       6, 1, 4, 9, 4, 7, 6, 7, 6, 8, 6, 0, 8, 8, 9, 6, 5, 1, 6, 4, 1, 6,\n",
              "       3, 3, 6, 4, 4, 2, 6, 3, 8, 3, 3, 3, 0, 6, 7, 5, 4, 1, 0, 4, 8, 9,\n",
              "       6, 4, 5, 0, 1, 4, 6, 9, 3, 3, 2, 9, 5, 3, 2, 3, 4, 6, 1, 3, 6, 9,\n",
              "       2, 4, 8, 3, 7, 6, 2, 9, 3, 0, 6, 9, 3, 6, 3, 8, 3, 0, 7, 6, 1, 1,\n",
              "       9, 7, 2, 7, 8, 5, 5, 7, 5, 2, 2, 7, 2, 7, 9, 9, 7, 0, 9, 3, 6, 8,\n",
              "       9, 7, 7, 3, 8, 8, 3, 6, 4, 1, 3, 2, 6, 8, 8, 8, 4, 6, 7, 5, 2, 4,\n",
              "       8, 8, 2, 4, 6, 9, 4, 4, 4, 3, 4, 6, 5, 9, 0, 1, 7, 2, 0, 9, 0, 6,\n",
              "       4, 2, 0, 7, 9, 8, 3, 7, 2, 1, 8, 7, 3, 7, 3, 6, 4, 1, 1, 1, 0, 8,\n",
              "       2, 1, 9, 8, 6, 8, 2, 7, 2, 1, 1, 1, 6, 4, 4, 0, 9, 4, 1, 1, 7, 2,\n",
              "       8, 9, 0, 6, 4, 8, 8, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "6xRiDvtx7Atw",
        "outputId": "c9476b20-84a9-4888-9b50-d66c83ef3b6f"
      },
      "source": [
        "# Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "\n",
        "index_array = [\n",
        "               ['Predicted Values']*10,\n",
        "               range(10)\n",
        "]\n",
        "index_tuples = list(zip(*index_array))\n",
        "index = pd.MultiIndex.from_tuples(index_tuples)\n",
        "\n",
        "column_array = [\n",
        "               ['Actual Values']*10,\n",
        "               range(10)\n",
        "]\n",
        "column_tuples = list(zip(*column_array))\n",
        "column = pd.MultiIndex.from_tuples(column_tuples)\n",
        "\n",
        "pd.DataFrame(confusion_matrix(y_test, y_test_predicted), index=index, columns=column)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"10\" halign=\"left\">Actual Values</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">Predicted Values</th>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Actual Values                                    \n",
              "                               0   1   2   3   4   5   6   7   8   9\n",
              "Predicted Values 0            20   0   2   0   1   0   2   0   2   0\n",
              "                 1             1  29   1   2   0   0   0   0   0   2\n",
              "                 2             1   1  26   5   0   1   1   0   1   0\n",
              "                 3             0   0   1  24   0   1   0   0   2   1\n",
              "                 4             0   0   0   0  25   0   0   3   1   1\n",
              "                 5             0   2   1   1   3  22   1   0   6   4\n",
              "                 6             1   1   0   1   1   1  39   0   0   0\n",
              "                 7             0   2   0   0   3   0   1  33   0   0\n",
              "                 8             0   5   3   1   4   0   2   0  24   0\n",
              "                 9             0   0   1   2   1   1   0   0   3  33"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60S2luHj7kfw",
        "outputId": "d2b2df65-ae94-40a9-f0b9-a472b5f94ca1"
      },
      "source": [
        "f1_score(y_test, y_test_predicted, average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7628529777626711"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "1dkk7QDm9p9T",
        "outputId": "ea2c688f-31a2-402f-f6b5-46a9596e5fb8"
      },
      "source": [
        "# Hyper-parameter tuning\n",
        "# 2 methods -> Grid Search and Random Search\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "# Grid Search is exhaustive\n",
        "parameters = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'min_samples_split': [2,3,4,5],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [50, 100, None]\n",
        "}\n",
        "\n",
        "random_forest = RandomForestClassifier()\n",
        "\n",
        "clf = GridSearchCV(random_forest, parameters)\n",
        "clf.fit(x_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-dae76714be63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_forest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m             \u001b[0mbeing\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myou\u001b[0m \u001b[0mmay\u001b[0m \u001b[0muse\u001b[0m \u001b[0m_split\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_yields_constant_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m         \u001b[0mExamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcandidate\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0mare\u001b[0m \u001b[0malso\u001b[0m \u001b[0mdisplayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m           \u001b[0mtogether\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstarting\u001b[0m \u001b[0mtime\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcomputation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m     \u001b[0mpre_dispatch\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2*n_jobs'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mControls\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mjobs\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mget\u001b[0m \u001b[0mdispatched\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;34m-\u001b[0m \u001b[0man\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                   \u001b[0mevaluate\u001b[0m \u001b[0mcandidates\u001b[0m \u001b[0mon\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m                   evaluate candidates on subsampled data (as done in the\n\u001b[0m\u001b[1;32m    690\u001b[0m                   SucessiveHaling estimators). By default, the original `cv`\n\u001b[1;32m    691\u001b[0m                   \u001b[0mparameter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mavailable\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mprivate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m         )\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0;31m# Check parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;31m# TODO: Remove in v1.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"building tree %d of %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtree_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m         \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m         \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mae\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                 warnings.warn(\n\u001b[0;32m--> 367\u001b[0;31m                     \u001b[0;34m\"Criterion 'mae' was deprecated in v1.0 and will be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m                     \u001b[0;34m\"removed in version 1.2. Use `criterion='absolute_error'` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                     \u001b[0;34m\"which is equivalent.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z7MzmDCB6FR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb442392-41df-4208-8760-a92f23ab686d"
      },
      "source": [
        "clf.best_params_ #get_params()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'entropy',\n",
              " 'max_depth': 50,\n",
              " 'min_samples_split': 3,\n",
              " 'n_estimators': 150}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cRGWH3hCs_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad15f8b-6d02-470c-ec7c-ae582fb7d6ac"
      },
      "source": [
        "# Grid Search is exhaustive\n",
        "parameters = {\n",
        "    'n_estimators': range(100, 1000),\n",
        "    'min_samples_split': [2,3,4,5],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [50, 100, None]\n",
        "}\n",
        "\n",
        "random_forest = RandomForestClassifier()\n",
        "\n",
        "clf = RandomizedSearchCV(random_forest, parameters, random_state=0, n_iter=5)\n",
        "clf.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=None, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=100,\n",
              "                                                    n_jobs=None,\n",
              "                                                    oob_score=False,\n",
              "                                                    random_state=None,\n",
              "                                                    verbose=0,\n",
              "                                                    warm_start=False),\n",
              "                   iid='deprecated', n_iter=5, n_jobs=None,\n",
              "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
              "                                        'max_depth': [50, 100, None],\n",
              "                                        'min_samples_split': [2, 3, 4, 5],\n",
              "                                        'n_estimators': range(100, 1000)},\n",
              "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf2eV-6MC_z9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1142348-6b40-4fdc-bafc-b1ebbb27e46f"
      },
      "source": [
        "clf.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'gini',\n",
              " 'max_depth': None,\n",
              " 'min_samples_split': 4,\n",
              " 'n_estimators': 945}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzDehc4iDYdP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "a28708d7-b474-44ae-c109-eedbf613d69b"
      },
      "source": [
        "# Get confusion matrix and f1 score after hyperparameter tuning\n",
        "\n",
        "y_test_predicted = clf.predict(x_test)\n",
        "\n",
        "print('F1 Score', f1_score(y_test, y_test_predicted, average='weighted'))\n",
        "pd.DataFrame(confusion_matrix(y_test, y_test_predicted), index=index, columns=column)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score 0.9749434374912246\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"10\" halign=\"left\">Actual Values</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">Predicted Values</th>\n",
              "      <th>0</th>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Actual Values                                    \n",
              "                               0   1   2   3   4   5   6   7   8   9\n",
              "Predicted Values 0            27   0   0   0   0   0   0   0   0   0\n",
              "                 1             0  35   0   0   0   0   0   0   0   0\n",
              "                 2             1   1  34   0   0   0   0   0   0   0\n",
              "                 3             0   0   0  29   0   0   0   0   0   0\n",
              "                 4             0   0   0   0  29   0   0   1   0   0\n",
              "                 5             0   0   0   0   0  39   0   0   0   1\n",
              "                 6             0   0   0   0   0   0  44   0   0   0\n",
              "                 7             0   0   0   0   0   0   0  39   0   0\n",
              "                 8             0   1   0   1   0   0   0   1  36   0\n",
              "                 9             0   0   0   1   0   1   0   0   0  39"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmMHeXf0EZHn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}